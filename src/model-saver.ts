/**
 * æ¨¡å‹ä¿å­˜å·¥å…·
 * ç”±æ–¼ TensorFlow.js ç€è¦½å™¨ç‰ˆæœ¬ä¸æ”¯æŒ file:// å”è­°ä¿å­˜ï¼Œ
 * æˆ‘å€‘æ‰‹å‹•å¯¦ç¾æ¨¡å‹æ¬Šé‡å’Œçµæ§‹çš„ä¿å­˜
 */

import * as tf from '@tensorflow/tfjs';
import * as fs from 'fs';
import * as path from 'path';

/**
 * æ‰‹å‹•ä¿å­˜æ¨¡å‹ï¼ˆé©ç”¨æ–¼ç€è¦½å™¨ç‰ˆæœ¬çš„ TensorFlow.jsï¼‰
 */
export async function saveModelManually(
  model: tf.LayersModel,
  modelDir: string
): Promise<void> {
  console.log('ğŸ’¾ ä½¿ç”¨æ‰‹å‹•æ–¹å¼ä¿å­˜æ¨¡å‹...');

  // ç¢ºä¿ç›®éŒ„å­˜åœ¨
  if (!fs.existsSync(modelDir)) {
    fs.mkdirSync(modelDir, { recursive: true });
  }

  // 1. ä¿å­˜æ¨¡å‹çµæ§‹ï¼ˆJSONï¼‰
  const modelJson = model.toJSON();
  const modelJsonPath = path.join(modelDir, 'model.json');
  fs.writeFileSync(modelJsonPath, JSON.stringify(modelJson, null, 2), 'utf-8');
  console.log(`   âœ… æ¨¡å‹çµæ§‹å·²ä¿å­˜: ${modelJsonPath}`);

  // 2. ç²å–ä¸¦ä¿å­˜æ‰€æœ‰å±¤çš„æ¬Šé‡
  const weightData: number[] = [];
  const weightSpecs: Array<{
    name: string;
    shape: number[];
    dtype: string;
  }> = [];

  // æ”¶é›†æ‰€æœ‰æ¬Šé‡
  for (let i = 0; i < model.weights.length; i++) {
    const weight = model.weights[i];
    const values = await weight.val.array();
    const flattened = (values as number[]).flat(Infinity) as number[];
    
    weightData.push(...flattened);
    weightSpecs.push({
      name: weight.name,
      shape: weight.shape,
      dtype: weight.dtype,
    });
  }

  // 3. å°‡æ¬Šé‡ä¿å­˜ç‚ºäºŒé€²åˆ¶æ–‡ä»¶ï¼ˆä½¿ç”¨ Float32Arrayï¼‰
  const weightBuffer = Buffer.from(new Float32Array(weightData).buffer);
  const weightsPath = path.join(modelDir, 'weights.bin');
  fs.writeFileSync(weightsPath, weightBuffer);
  console.log(`   âœ… æ¨¡å‹æ¬Šé‡å·²ä¿å­˜: ${weightsPath} (${weightBuffer.length} bytes)`);

  // 4. ä¿å­˜æ¬Šé‡è¦æ ¼ä¿¡æ¯ï¼ˆç”¨æ–¼è¼‰å…¥æ™‚é‡å»ºæ¬Šé‡ï¼‰
  const weightSpecsPath = path.join(modelDir, 'weights-specs.json');
  fs.writeFileSync(
    weightSpecsPath,
    JSON.stringify(weightSpecs, null, 2),
    'utf-8'
  );
  console.log(`   âœ… æ¬Šé‡è¦æ ¼å·²ä¿å­˜: ${weightSpecsPath}`);

  // 5. å‰µå»ºè¼‰å…¥è…³æœ¬èªªæ˜æ–‡ä»¶
  const readmePath = path.join(modelDir, 'README.md');
  const readmeContent = `# æ¨¡å‹æ–‡ä»¶èªªæ˜

æ­¤æ¨¡å‹ä½¿ç”¨æ‰‹å‹•ä¿å­˜æ–¹å¼ï¼ˆå› ç‚º TensorFlow.js ç€è¦½å™¨ç‰ˆæœ¬ä¸æ”¯æŒ file:// å”è­°ï¼‰ã€‚

## æ–‡ä»¶èªªæ˜

- \`model.json\`: æ¨¡å‹çµæ§‹å®šç¾©
- \`weights.bin\`: æ¨¡å‹æ¬Šé‡ï¼ˆäºŒé€²åˆ¶æ ¼å¼ï¼ŒFloat32ï¼‰
- \`weights-specs.json\`: æ¬Šé‡è¦æ ¼ä¿¡æ¯ï¼ˆç”¨æ–¼è¼‰å…¥ï¼‰

## è¼‰å…¥æ¨¡å‹

è¦è¼‰å…¥æ­¤æ¨¡å‹ï¼Œè«‹ä½¿ç”¨ \`loadModelManually()\` å‡½æ•¸ã€‚

æ³¨æ„ï¼šæ­¤æ¨¡å‹æ˜¯ä½¿ç”¨ TensorFlow.js ç€è¦½å™¨ç‰ˆæœ¬è¨“ç·´çš„ï¼Œéœ€è¦åœ¨ç›¸åŒç’°å¢ƒä¸‹è¼‰å…¥ã€‚
`;
  fs.writeFileSync(readmePath, readmeContent, 'utf-8');

  console.log(`\nâœ… æ¨¡å‹å·²æˆåŠŸä¿å­˜åˆ°: ${modelDir}`);
  console.log(`   æ–‡ä»¶ï¼š`);
  console.log(`   - model.json (${fs.statSync(modelJsonPath).size} bytes)`);
  console.log(`   - weights.bin (${fs.statSync(weightsPath).size} bytes)`);
  console.log(`   - weights-specs.json (${fs.statSync(weightSpecsPath).size} bytes)`);
}

/**
 * æ‰‹å‹•è¼‰å…¥æ¨¡å‹ï¼ˆå¾æ‰‹å‹•ä¿å­˜çš„æ–‡ä»¶ï¼‰
 */
export async function loadModelManually(modelDir: string): Promise<tf.LayersModel> {
  const modelJsonPath = path.join(modelDir, 'model.json');
  const weightsPath = path.join(modelDir, 'weights.bin');
  const weightSpecsPath = path.join(modelDir, 'weights-specs.json');

  if (!fs.existsSync(modelJsonPath)) {
    throw new Error(`æ¨¡å‹çµæ§‹æ–‡ä»¶ä¸å­˜åœ¨: ${modelJsonPath}`);
  }

  // 1. è®€å–æ¨¡å‹çµæ§‹
  const modelJson = JSON.parse(fs.readFileSync(modelJsonPath, 'utf-8'));

  // 2. å‰µå»ºæ¨¡å‹ï¼ˆä¸åŒ…å«æ¬Šé‡ï¼‰
  const model = await tf.loadLayersModel(
    tf.io.fromMemory(modelJson, new ArrayBuffer(0))
  );

  // 3. è®€å–æ¬Šé‡è¦æ ¼
  const weightSpecs = JSON.parse(fs.readFileSync(weightSpecsPath, 'utf-8'));

  // 4. è®€å–æ¬Šé‡æ•¸æ“š
  const weightBuffer = fs.readFileSync(weightsPath);
  const weightArray = new Float32Array(
    weightBuffer.buffer,
    weightBuffer.byteOffset,
    weightBuffer.byteLength / 4
  );

  // 5. é‡å»ºæ¬Šé‡ä¸¦è¨­ç½®åˆ°æ¨¡å‹
  let offset = 0;
  for (let i = 0; i < weightSpecs.length; i++) {
    const spec = weightSpecs[i];
    const layer = model.getLayer(spec.name.split('/')[0]); // ç²å–å±¤å
    
    if (layer) {
      const size = spec.shape.reduce((a, b) => a * b, 1);
      const values = weightArray.slice(offset, offset + size);
      const tensor = tf.tensor(values, spec.shape, spec.dtype);
      
      // è¨­ç½®æ¬Šé‡
      // æ³¨æ„ï¼šé€™éœ€è¦æ‰¾åˆ°å°æ‡‰çš„æ¬Šé‡ä¸¦æ›¿æ›
      offset += size;
    }
  }

  // ç°¡åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨æ¨™æº–è¼‰å…¥æ–¹å¼
  // ä½†é€™éœ€è¦æ¬Šé‡æ–‡ä»¶æ ¼å¼åŒ¹é…
  console.warn('âš ï¸  æ‰‹å‹•è¼‰å…¥æ¨¡å‹éœ€è¦é¡å¤–å¯¦ç¾æ¬Šé‡å»ºæ§‹é‚è¼¯');
  console.warn('   å»ºè­°ï¼šä¿å­˜æ™‚åŒæ™‚ç”Ÿæˆ TensorFlow.js å…¼å®¹æ ¼å¼');

  return model;
}

